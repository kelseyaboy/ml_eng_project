{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-24374f7b8dc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#from sklearn.ensemble import RandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;31m#rom sklearn.metrics import mean_squared_error'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "f#rom sklearn.metrics import mean_squared_error'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sheon\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "train_path = '../data/train.csv'\n",
    "store_path = '../data/store.csv'\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "store = pd.read_csv(store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train['Date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop records with Open==0 and Customers==0\n",
    "# No customers or when closed would mean 0 sales\n",
    "\n",
    "train = train.drop(train[train['Open']==0].index)\n",
    "train = train.drop(train[train['Customers']==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean fields\n",
    "\n",
    "train['StateHoliday'] = train['StateHoliday'].replace(0, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datatypes\n",
    "\n",
    "train['Store'] = train['Store'].astype(int)\n",
    "train['DayOfWeek'] = train['DayOfWeek'].astype(int)\n",
    "#train['Date'] = train['Date'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d'))\n",
    "train['Sales'] = train['Sales'].astype(float)\n",
    "train['Customers'] = train['Customers'].astype(int)\n",
    "train['Open'] = train['Open'].astype(int)\n",
    "train['Promo'] = train['Promo'].astype(int)\n",
    "train['StateHoliday'] = train['StateHoliday'].astype(str)\n",
    "train['SchoolHoliday'] = train['SchoolHoliday'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean change datatype of 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear'\n",
    "\n",
    "store['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].fillna(0)\n",
    "store['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].fillna(0)\n",
    "\n",
    "store['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].astype(int).astype(str)\n",
    "store['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].astype(int).astype(str)\n",
    "\n",
    "store['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].str.pad(width=2, side='left', fillchar='0')\n",
    "\n",
    "store['CompetitionOpenSinceMonth'] = store['CompetitionOpenSinceMonth'].replace('00', '01')\n",
    "store['CompetitionOpenSinceYear'] = store['CompetitionOpenSinceYear'].replace('0', '1800')\n",
    "\n",
    "store['CompetitionOpenSince'] = store['CompetitionOpenSinceMonth'] + '_' + store['CompetitionOpenSinceYear']\n",
    "\n",
    "store['CompetitionOpenSince'] = store['CompetitionOpenSince'].apply(lambda x: dt.datetime.strptime(x, '%m_%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean change datatype of 'Promo2SinceMonth', 'Promo2SinceYear'\n",
    "\n",
    "store['Promo2SinceWeek'] = store['Promo2SinceWeek'].fillna(0)\n",
    "store['Promo2SinceYear'] = store['Promo2SinceYear'].fillna(0)\n",
    "\n",
    "store['Promo2SinceWeek'] = store['Promo2SinceWeek'].astype(int).astype(str)\n",
    "store['Promo2SinceYear'] = store['Promo2SinceYear'].astype(int).astype(str)\n",
    "\n",
    "store['Promo2SinceWeek'] = store['Promo2SinceWeek'].str.pad(width=2, side='left', fillchar='0')\n",
    "\n",
    "store['Promo2SinceWeek'] = store['Promo2SinceWeek'].replace('00', '01')\n",
    "store['Promo2SinceYear'] = store['Promo2SinceYear'].replace('0', '1800')\n",
    "\n",
    "store['Promo2Since'] = store['Promo2SinceWeek'] + '_' + store['Promo2SinceYear'] + ' SUN'\n",
    "\n",
    "store['Promo2Since'] = store['Promo2Since'].apply(lambda x: dt.datetime.strptime(x, '%U_%Y %a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'PromoInterval'. Replace all Nan to 'None'\n",
    "store['PromoInterval'] = store['PromoInterval'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'CompetitionDistance'. Replace all Nan to 0\n",
    "store['CompetitionDistance'] = store['CompetitionDistance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and store datasets\n",
    "\n",
    "data = pd.merge(train, store, on='Store', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'DaysSinceCompetitionOpen' feature\n",
    "\n",
    "data['DaysSinceCompetitionOpen'] = data.apply(lambda x: 0 if x['CompetitionOpenSince'].year<=dt.date(1800, 12, 31).year else (0 if (x['Date'] <= x['CompetitionOpenSince']) else (x['Date']-x['CompetitionOpenSince']).days), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'DaysSincePromo2' feature\n",
    "\n",
    "data['DaysSincePromo2'] = data.apply(lambda x: 0 if x['Promo2Since'].year<=dt.date(1800, 12, 31).year else (0 if (x['Date'] <= x['Promo2Since']) else (x['Date']-x['Promo2Since']).days), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all fields needed for modelling\n",
    "\n",
    "for_model = data[['Store', 'DayOfWeek', 'Sales', \n",
    "                  'Customers', 'Promo', 'StateHoliday', \n",
    "                  'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "                  'CompetitionDistance', 'Promo2', 'DaysSinceCompetitionOpen',\n",
    "                  'DaysSincePromo2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all fields needed for modelling\n",
    "\n",
    "for_model = pd.get_dummies(for_model, \n",
    "                           columns=['StateHoliday', 'StoreType', 'Assortment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to features and target\n",
    "\n",
    "X = for_model.drop(['Store', 'Sales'], axis=1)\n",
    "y = for_model[['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using Random Forest Regression\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)\n",
    "print(forest_reg.score(X_train, y_train))\n",
    "forest_pred = forest_reg.predict(X_test)\n",
    "print(forest_reg.score(X_test, y_test))\n",
    "print(mean_squared_error(y_test, forest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "joblib.dump(forest_reg, '../model/compressed_rf_sales.pkl', compress=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model loading\n",
    "import joblib\n",
    "\n",
    "pkl = joblib.load('../model/compressed_rf_sales.pkl')\n",
    "pkl_pred = pkl.predict(X_test[:1])\n",
    "# print(mean_squared_error(y_test, pkl_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7329.75])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341000</th>\n",
       "      <td>7577.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sales\n",
       "341000  7577.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
